{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyP72r/CbdPhn7gBgGv7shKQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import shutil\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"z8prLv49XrcG","executionInfo":{"status":"ok","timestamp":1753548086255,"user_tz":-330,"elapsed":20929,"user":{"displayName":"sye far","userId":"17480999233824993672"}},"outputId":"703c3c34-c418-463d-bfdc-6f586d628167"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import zipfile\n","import os\n","import cv2\n","import numpy as np\n","from pathlib import Path\n","from sklearn.model_selection import train_test_split  # Added explicit import\n","from sklearn.preprocessing import StandardScaler\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torch.cuda.amp import autocast, GradScaler"],"metadata":{"id":"tyPxhvyuXtW2","executionInfo":{"status":"ok","timestamp":1753548096333,"user_tz":-330,"elapsed":10081,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Copy cropsobel folder\n","src_cropsobel = '/content/drive/MyDrive/Colab Notebooks/Dental Scans/cropsobel'\n","dst_cropsobel = '/content/cropsobel'\n","try:\n","    shutil.copytree(src_cropsobel, dst_cropsobel, dirs_exist_ok=True)\n","    print(\"✅ Copied cropsobel folder to /content/cropsobel\")\n","except Exception as e:\n","    print(f\"Error copying cropsobel folder: {e}\")\n","    exit()\n","\n","# Extract training dataset\n","extract_path = '/content/dataset'\n","os.makedirs(extract_path, exist_ok=True)\n","zip_path = '/content/drive/MyDrive/Colab Notebooks/Dental Scans/cropped_jaw_dataset_sobel.zip'\n","\n","try:\n","    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n","        zip_ref.extractall(extract_path)\n","    print(\"✅ Training dataset extraction complete!\")\n","except FileNotFoundError:\n","    print(f\"Error: Could not find the file at: {zip_path}\")\n","    exit()\n","except Exception as e:\n","    print(f\"Error extracting dataset: {e}\")\n","    exit()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"994Out7SXvW8","executionInfo":{"status":"ok","timestamp":1753548111807,"user_tz":-330,"elapsed":15475,"user":{"displayName":"sye far","userId":"17480999233824993672"}},"outputId":"e71ffd4c-9697-44ae-f857-60345b632e48"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Copied cropsobel folder to /content/cropsobel\n","✅ Training dataset extraction complete!\n"]}]},{"cell_type":"code","source":["# Define paths\n","dataset_path = Path(extract_path) / \"cropped_jaw_dataset_sobel\"\n","test_path = Path(\"/content/cropsobel\")\n","subfolders = [\"above40\", \"AdditionalAbove40\", \"age17-40\", \"AdditionalAge17-40\"]\n","output_path = Path(extract_path) / \"clustered_autoencoder\"\n","test_output_path = Path(\"/content/classify\")\n","basket_normal = output_path / \"normal\"\n","basket_osteoporotic = output_path / \"osteoporotic\"\n","test_basket_normal = test_output_path / \"normal\"\n","test_basket_osteoporotic = test_output_path / \"osteoporosis\""],"metadata":{"id":"capgBWQxXw7t","executionInfo":{"status":"ok","timestamp":1753548111840,"user_tz":-330,"elapsed":22,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["# Create output directories\n","for path in [basket_normal, basket_osteoporotic, test_basket_normal, test_basket_osteoporotic]:\n","    path.mkdir(parents=True, exist_ok=True)\n","\n","# Custom Dataset\n","class OPGDataset(Dataset):\n","    def __init__(self, image_paths, labels=None, img_size=(128, 128), is_test=False):\n","        self.image_paths = image_paths\n","        self.labels = labels\n","        self.is_test = is_test\n","        self.transform = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.5,), (0.5,)),\n","            transforms.Lambda(lambda x: x.float()),\n","            *([] if is_test else [\n","                transforms.RandomRotation(10),\n","                transforms.RandomHorizontalFlip(),\n","                transforms.RandomAffine(degrees=0, scale=(0.9, 1.1))\n","            ])\n","        ])\n","        self.img_size = img_size\n","        self.folder_map = {str(p): s for s in subfolders for p in (dataset_path / s).glob(\"*.jpg\")}\n","\n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        img = cv2.imread(str(self.image_paths[idx]), cv2.IMREAD_GRAYSCALE)\n","        if img is None:\n","            raise ValueError(f\"Failed to load image: {self.image_paths[idx]}\")\n","        img = cv2.resize(img, self.img_size)\n","        img = img / 255.0\n","        img = self.transform(img)\n","        intensity = img.mean().item()\n","        if self.is_test:\n","            return img, intensity, str(self.image_paths[idx])\n","        return img, intensity, self.labels[idx] if self.labels is not None else 0\n"],"metadata":{"id":"inijAJGYXzUl","executionInfo":{"status":"ok","timestamp":1753548111855,"user_tz":-330,"elapsed":11,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["\n","# CNN Model\n","class CNN(nn.Module):\n","    def __init__(self):\n","        super(CNN, self).__init__()\n","        self.convnet = nn.Sequential(\n","            nn.Conv2d(1, 16, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            nn.Conv2d(16, 32, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            nn.Conv2d(32, 64, 3, padding=1),\n","            nn.ReLU(),\n","            nn.MaxPool2d(2, 2),\n","            nn.Flatten(),\n","            nn.Linear(64 * 16 * 16, 128),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","            nn.Linear(128, 2)\n","        )\n","\n","    def forward(self, x):\n","        return self.convnet(x)"],"metadata":{"id":"rHt2vPEXX05t","executionInfo":{"status":"ok","timestamp":1753548111875,"user_tz":-330,"elapsed":17,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["# Load image paths and assign pseudo-labels\n","train_image_paths = []\n","train_labels = []\n","train_intensities = []\n","below_40 = [\"age17-40\", \"AdditionalAge17-40\"]\n","above_40 = [\"above40\", \"AdditionalAbove40\"]\n","\n","for subfolder in subfolders:\n","    input_dir = dataset_path / subfolder\n","    for img_path in input_dir.glob(\"*.jpg\"):\n","        img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)\n","        if img is not None:\n","            train_image_paths.append(img_path)\n","            train_intensities.append(img.mean())\n","            if subfolder in below_40:\n","                train_labels.append(0)  # 100% normal\n","            else:\n","                # 85% osteoporotic, 15% normal\n","                train_labels.append(1 if np.random.rand() < 0.85 else 0)\n","\n","# Verify counts\n","if len(train_image_paths) != 396:\n","    print(f\"Error: Found {len(train_image_paths)} training images, expected 396. Exiting.\")\n","    exit()\n","if len(train_labels) != 396 or len(train_intensities) != 396:\n","    print(f\"Error: Inconsistent lengths - Images: {len(train_image_paths)}, Labels: {len(train_labels)}, Intensities: {len(train_intensities)}. Exiting.\")\n","    exit()\n"],"metadata":{"id":"ca7pC4HwX3C8","executionInfo":{"status":"ok","timestamp":1753548113580,"user_tz":-330,"elapsed":1702,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"6cd1bfc4","executionInfo":{"status":"ok","timestamp":1753548113620,"user_tz":-330,"elapsed":4,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"source":["# Load test image paths\n","test_image_paths = list(test_path.glob(\"*.jpg\"))\n","\n","# Verify counts\n","if len(train_image_paths) != 396:\n","    print(f\"Error: Found {len(train_image_paths)} training images, expected 396. Exiting.\")\n","    exit()\n","if len(test_image_paths) != 13:\n","    print(f\"Error: Found {len(test_image_paths)} test images, expected 13. Exiting.\")\n","    exit()"],"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Verify counts\n","if len(train_image_paths) != 396:\n","    print(f\"Error: Found {len(train_image_paths)} training images, expected 396. Exiting.\")\n","    exit()\n","if len(test_image_paths) != 13:\n","    print(f\"Error: Found {len(test_image_paths)} test images, expected 13. Exiting.\")\n","    exit()"],"metadata":{"id":"oDeH9cecX4tF","executionInfo":{"status":"ok","timestamp":1753548113629,"user_tz":-330,"elapsed":7,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["# Split training data\n","train_idx, val_idx = train_test_split(range(396), test_size=0.2, stratify=train_labels, random_state=42)\n","train_paths = [train_image_paths[i] for i in train_idx]\n","val_paths = [train_image_paths[i] for i in val_idx]\n","val_labels = [train_labels[i] for i in val_idx] # Create val_labels from original train_labels\n","train_labels = [train_labels[i] for i in train_idx] # Then update train_labels"],"metadata":{"id":"wDacRHG1X5v0","executionInfo":{"status":"ok","timestamp":1753548113634,"user_tz":-330,"elapsed":2,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["# Create datasets\n","try:\n","    train_dataset = OPGDataset(train_paths, train_labels)\n","    val_dataset = OPGDataset(val_paths, val_labels)\n","    test_dataset = OPGDataset(test_image_paths, is_test=True)\n","    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n","except Exception as e:\n","    print(f\"Error creating datasets: {e}\")\n","    exit()\n","\n","# Initialize model and optimizer\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","try:\n","    model = CNN().to(device)\n","    criterion = nn.CrossEntropyLoss(weight=torch.tensor([0.15, 0.85]).to(device))  # Weighted for 85% osteo\n","    optimizer = optim.Adam(model.parameters(), lr=0.001)\n","    scaler = GradScaler()\n","except Exception as e:\n","    print(f\"Error initializing model: {e}\")\n","    exit()\n"],"metadata":{"id":"BcDMLvrxX7P0","executionInfo":{"status":"ok","timestamp":1753548113839,"user_tz":-330,"elapsed":203,"user":{"displayName":"sye far","userId":"17480999233824993672"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d51c01dd-72c2-43f9-cb0f-af20a8db85e7"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-11-1458724554.py:19: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n","  scaler = GradScaler()\n"]}]},{"cell_type":"code","source":["# Train CNN\n","num_epochs = 50\n","best_val_acc = 0.0\n","try:\n","    for epoch in range(num_epochs):\n","        model.train()\n","        running_loss = 0.0\n","        for images, _, labels in train_loader:\n","            images, labels = images.to(device), labels.to(device)\n","            optimizer.zero_grad()\n","            with autocast():\n","                outputs = model(images)\n","                loss = criterion(outputs, labels)\n","            scaler.scale(loss).backward()\n","            scaler.unscale_(optimizer)\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            scaler.step(optimizer)\n","            scaler.update()\n","            running_loss += loss.item()\n","\n","        # Validation\n","        model.eval()\n","        correct = 0\n","        total = 0\n","        with torch.no_grad():\n","            for images, _, labels in val_loader:\n","                images, labels = images.to(device), labels.to(device)\n","                outputs = model(images)\n","                _, predicted = torch.max(outputs, 1)\n","                total += labels.size(0)\n","                correct += (predicted == labels).sum().item()\n","        val_acc = correct / total\n","        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}, Val Acc: {val_acc:.4f}\")\n","\n","        # Save checkpoint\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","            torch.save(model.state_dict(), '/content/model_checkpoint.pth')\n","\n","        torch.cuda.empty_cache()\n","except Exception as e:\n","    print(f\"Error during training: {e}\")\n","    exit()"],"metadata":{"id":"1eL-Y5y8X9TM","executionInfo":{"status":"ok","timestamp":1753548256170,"user_tz":-330,"elapsed":142322,"user":{"displayName":"sye far","userId":"17480999233824993672"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"3c6a77fc-ba2c-4ea4-9c40-5f7b33e7410c"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-12-3000357972.py:11: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n","  with autocast():\n"]},{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Loss: 0.3447, Val Acc: 0.6500\n","Epoch [2/50], Loss: 0.3650, Val Acc: 0.6500\n","Epoch [3/50], Loss: 0.3507, Val Acc: 0.6500\n","Epoch [4/50], Loss: 0.3287, Val Acc: 0.6500\n","Epoch [5/50], Loss: 0.3397, Val Acc: 0.6500\n","Epoch [6/50], Loss: 0.3072, Val Acc: 0.6500\n","Epoch [7/50], Loss: 0.3468, Val Acc: 0.6500\n","Epoch [8/50], Loss: 0.2677, Val Acc: 0.6500\n","Epoch [9/50], Loss: 0.2725, Val Acc: 0.6500\n","Epoch [10/50], Loss: 0.2696, Val Acc: 0.6750\n","Epoch [11/50], Loss: 0.2783, Val Acc: 0.6500\n","Epoch [12/50], Loss: 0.2821, Val Acc: 0.6875\n","Epoch [13/50], Loss: 0.2441, Val Acc: 0.6875\n","Epoch [14/50], Loss: 0.3098, Val Acc: 0.6500\n","Epoch [15/50], Loss: 0.2699, Val Acc: 0.6500\n","Epoch [16/50], Loss: 0.2553, Val Acc: 0.7250\n","Epoch [17/50], Loss: 0.2821, Val Acc: 0.7500\n","Epoch [18/50], Loss: 0.2333, Val Acc: 0.7500\n","Epoch [19/50], Loss: 0.2547, Val Acc: 0.7500\n","Epoch [20/50], Loss: 0.2254, Val Acc: 0.7750\n","Epoch [21/50], Loss: 0.2135, Val Acc: 0.7625\n","Epoch [22/50], Loss: 0.2248, Val Acc: 0.7250\n","Epoch [23/50], Loss: 0.2009, Val Acc: 0.7500\n","Epoch [24/50], Loss: 0.2124, Val Acc: 0.7500\n","Epoch [25/50], Loss: 0.2358, Val Acc: 0.7625\n","Epoch [26/50], Loss: 0.2150, Val Acc: 0.8000\n","Epoch [27/50], Loss: 0.2327, Val Acc: 0.7500\n","Epoch [28/50], Loss: 0.2283, Val Acc: 0.7625\n","Epoch [29/50], Loss: 0.2030, Val Acc: 0.7375\n","Epoch [30/50], Loss: 0.2074, Val Acc: 0.7375\n","Epoch [31/50], Loss: 0.1891, Val Acc: 0.7375\n","Epoch [32/50], Loss: 0.1840, Val Acc: 0.7875\n","Epoch [33/50], Loss: 0.1824, Val Acc: 0.7500\n","Epoch [34/50], Loss: 0.1952, Val Acc: 0.8000\n","Epoch [35/50], Loss: 0.1634, Val Acc: 0.8125\n","Epoch [36/50], Loss: 0.1743, Val Acc: 0.7750\n","Epoch [37/50], Loss: 0.1704, Val Acc: 0.8000\n","Epoch [38/50], Loss: 0.1672, Val Acc: 0.8125\n","Epoch [39/50], Loss: 0.1518, Val Acc: 0.7875\n","Epoch [40/50], Loss: 0.1816, Val Acc: 0.8000\n","Epoch [41/50], Loss: 0.1662, Val Acc: 0.7625\n","Epoch [42/50], Loss: 0.1551, Val Acc: 0.8000\n","Epoch [43/50], Loss: 0.1901, Val Acc: 0.7875\n","Epoch [44/50], Loss: 0.1727, Val Acc: 0.8000\n","Epoch [45/50], Loss: 0.1656, Val Acc: 0.8000\n","Epoch [46/50], Loss: 0.1376, Val Acc: 0.7625\n","Epoch [47/50], Loss: 0.1605, Val Acc: 0.7875\n","Epoch [48/50], Loss: 0.1302, Val Acc: 0.7875\n","Epoch [49/50], Loss: 0.1322, Val Acc: 0.8000\n","Epoch [50/50], Loss: 0.1559, Val Acc: 0.7750\n"]}]},{"cell_type":"code","source":["# Load best model\n","try:\n","    model.load_state_dict(torch.load('/content/model_checkpoint.pth'))\n","except Exception as e:\n","    print(f\"Error loading checkpoint: {e}\")\n","    exit()\n"],"metadata":{"id":"-lLZX5gCX_Bk","executionInfo":{"status":"ok","timestamp":1753548256191,"user_tz":-330,"elapsed":19,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# --- Save the final model weights ---\n","\n","# Define the destination path and filename as requested\n","destination_location = \"/content/drive/MyDrive/Colab Notebooks/Dental Scans/Labeled /CNN model\"\n","file_name = \"CNN_WEIGHTS_DENTAL_SCANS.H5\"\n","full_path = os.path.join(destination_location, file_name)\n","\n","# Ensure the destination directory exists, creating it if necessary\n","os.makedirs(destination_location, exist_ok=True)\n","\n","# Save the model's state dictionary (weights and biases) to the specified file.\n","# Note: While the .h5 extension is commonly associated with Keras/TensorFlow,\n","# torch.save will save the PyTorch model's parameters in its own format.\n","torch.save(model.state_dict(), full_path)\n","\n","print(f\"✅ Model weights saved successfully to: {full_path}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UpZM89OGlZox","executionInfo":{"status":"ok","timestamp":1753548256240,"user_tz":-330,"elapsed":46,"user":{"displayName":"sye far","userId":"17480999233824993672"}},"outputId":"0d452061-e5a5-4943-f247-2620e98377fc"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["✅ Model weights saved successfully to: /content/drive/MyDrive/Colab Notebooks/Dental Scans/Labeled /CNN model/CNN_WEIGHTS_DENTAL_SCANS.H5\n"]}]},{"cell_type":"code","source":["# Test classification\n","model.eval()\n","test_predictions = []\n","test_likelihoods = []\n","test_paths = []\n","try:\n","    with torch.no_grad():\n","        for images, intensities, paths in test_loader:\n","            images = images.to(device)\n","            outputs = model(images)\n","            probs = torch.softmax(outputs, dim=1)[:, 1].cpu().numpy()  # Osteoporotic prob\n","            for prob, intensity, path in zip(probs, intensities, paths):\n","                likelihood = min(max(prob + 0.15 * (intensity / 255.0), 0.0), 1.0)\n","                test_likelihoods.append(likelihood)\n","                test_predictions.append(1 if likelihood > 0.5 else 0)\n","                test_paths.append(path)\n","except Exception as e:\n","    print(f\"Error during testing: {e}\")\n","    exit()"],"metadata":{"id":"PxtHNu9cYAx1","executionInfo":{"status":"ok","timestamp":1753548256330,"user_tz":-330,"elapsed":86,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"execution_count":15,"outputs":[]},{"cell_type":"code","source":["# Save test images to baskets\n","for path, pred in zip(test_paths, test_predictions):\n","    img = cv2.imread(path)\n","    if img is None:\n","        print(f\"Warning: Failed to save {Path(path).name}\")\n","        continue\n","    output_dir = test_basket_osteoporotic if pred == 1 else test_basket_normal\n","    output_path = output_dir / Path(path).name\n","    cv2.imwrite(str(output_path), img)"],"metadata":{"id":"OxIx_bweYCld","executionInfo":{"status":"ok","timestamp":1753548256476,"user_tz":-330,"elapsed":137,"user":{"displayName":"sye far","userId":"17480999233824993672"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["# Save test classification summary\n","with open(test_output_path / \"test_classification_summary.txt\", \"w\") as f:\n","    f.write(f\"Images in Test Normal basket: {sum(1 for p in test_predictions if p == 0)}\\n\")\n","    f.write(f\"Images in Test Osteoporotic basket: {sum(1 for p in test_predictions if p == 1)}\\n\")\n","    f.write(\"\\nOsteoporosis Likelihoods:\\n\")\n","    for path, likelihood in zip(test_paths, test_likelihoods):\n","        f.write(f\"Image: {Path(path).name}, Likelihood of Osteoporosis: {likelihood:.2%}\\n\")\n","\n","print(\"CNN classification complete. Check 'clustered_autoencoder' and 'classify' folders.\")"],"metadata":{"id":"kENsXm61YEO8","executionInfo":{"status":"ok","timestamp":1753548256546,"user_tz":-330,"elapsed":59,"user":{"displayName":"sye far","userId":"17480999233824993672"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"945222b2-c197-4e6d-accb-16ce49d82033"},"execution_count":17,"outputs":[{"output_type":"stream","name":"stdout","text":["CNN classification complete. Check 'clustered_autoencoder' and 'classify' folders.\n"]}]}]}